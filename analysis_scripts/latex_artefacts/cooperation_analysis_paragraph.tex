The cooperation rates detailed in Table \ref{tab:cooperation_rates_updated} reveal striking behavioral patterns that contradict standard game-theoretic predictions for short-horizon interactions. Most LLM models maintain remarkably high cooperation rates in the 75\% shadow condition (shortest games, 1.33 expected rounds), with Mistral-Medium exhibiting near-perfect cooperation (0.96-1.00) and Claude4-Sonnet showing strong cooperative tendencies (0.89-0.97). Agent rationale analysis reveals that LLMs often misinterpret game dynamics: Claude agents consistently calculate expected game length as "about 4 rounds" despite the 75\% termination probability yielding only 1.33 rounds, while Mistral agents focus on "fostering cooperation" and "long-term payoff maximization" even in contexts where game theory predicts immediate defection should dominate. Only GPT5mini demonstrates sophisticated strategic adaptability, dramatically shifting from high cooperation in longer games (0.86-0.91 in 5-25\% shadow) to predominantly defective behavior in 75\% shadow (0.149-0.167), with reasoning explicitly acknowledging that "future rewards are too small to overcome immediate advantage of defecting." Memory mode effects remain modest across most models, though Mistral shows slight improvements in tracking mode, while temperature variations produce minimal cooperation changes within individual models, suggesting that cooperative tendencies are deeply embedded in these models' strategic reasoning rather than being artifacts of sampling parameters.